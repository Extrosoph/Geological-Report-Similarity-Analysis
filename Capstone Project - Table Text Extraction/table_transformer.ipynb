{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score,confusion_matrix, f1_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing and OCR\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Transformers and huggingface_hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import DetrFeatureExtractor, TableTransformerForObjectDetection\n",
    "\n",
    "# PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH = 'C:/Users/nick2/Desktop/Capstone TT/Geological-Report-Similarity-Analysis' ## Path To Repository \n",
    "TESSERACT_PATH = r'C:/Program Files/Tesseract-OCR/tesseract' ## Path To Tesseract OCR - See README For Setup \n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "test_labels = pd.read_csv(os.path.join(DATA_PATH, 'Capstone Project - Table Text Extraction/Labeled Data.csv'))\n",
    "test_labels['Pred'] = None\n",
    "\n",
    "# Set working directory\n",
    "working_directory = os.path.join(DATA_PATH, 'WAMEX_DATA_EXTRACTED')\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Set tesseract path\n",
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH\n",
    "\n",
    "# List all files and get their full paths\n",
    "files = os.listdir()\n",
    "concatenated_paths = [os.path.join(working_directory, filename) for filename in files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Table Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_EXTENSIONS = {'.jpg', '.png'}\n",
    "COLORS = [\n",
    "    [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "    [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]\n",
    "]\n",
    "\n",
    "# Define Model and Feature Extractor\n",
    "feature_extractor = DetrFeatureExtractor()\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "# Functions\n",
    "def get_valid_images(directory):\n",
    "    \"\"\"Get valid image files from a directory.\"\"\"\n",
    "    all_files = [os.path.join(directory, file) for file in os.listdir(directory)\n",
    "                 if os.path.isfile(os.path.join(directory, file))\n",
    "                 and os.path.splitext(file)[1].lower() in VALID_EXTENSIONS]\n",
    "    return all_files\n",
    "\n",
    "\n",
    "def move_jpg_to_extracted_folder(directory):\n",
    "    \"\"\"Move all JPG files in a directory to a sub-directory named 'jpg_extracted'.\"\"\"\n",
    "    jpg_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.lower().endswith('.jpg')]\n",
    "    \n",
    "    # Create 'jpg_extracted' sub-directory if it doesn't exist\n",
    "    extracted_folder = os.path.join(directory, \"jpg_extracted\")\n",
    "    if not os.path.exists(extracted_folder):\n",
    "        os.makedirs(extracted_folder)\n",
    "\n",
    "    # Move each JPG file to the 'jpg_extracted' folder\n",
    "    for jpg_file in jpg_files:\n",
    "        shutil.move(os.path.join(directory, jpg_file), os.path.join(extracted_folder, jpg_file))\n",
    "\n",
    "\n",
    "\n",
    "def process_directory(directory, plot=False):\n",
    "    \"\"\"Process all valid images in a directory and return a DataFrame.\"\"\"\n",
    "    print(f\"Processing images in directory: {os.path.basename(directory)}\")\n",
    "    \n",
    "    all_files = get_valid_images(directory)\n",
    "    all_data = []\n",
    "    \n",
    "    for image_file in all_files:\n",
    "        data = process_image(image_file, base_save_path=directory, plot=plot)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "\n",
    "    # Move the JPG files to the 'jpg_extracted' folder after processing\n",
    "    move_jpg_to_extracted_folder(directory)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "def process_image(file_name, base_save_path, buffer=50, plot=True):\n",
    "    base_file_name = os.path.basename(file_name).rsplit('.', 1)[0]\n",
    "    file_parts = base_file_name.split('_')\n",
    "    \n",
    "    image = Image.open(file_name).convert(\"RGB\")\n",
    "    img_cv = cv2.imread(file_name)\n",
    "    width, height = image.size\n",
    "    encoding = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.94, target_sizes=[(height, width)])[0]\n",
    "    num_tables = len(results['scores'])\n",
    "\n",
    "    boxes = results['boxes'] # Direct extraction from results\n",
    "    if len(boxes) > 0:\n",
    "        specific_save_path = os.path.join(base_save_path, f\"{base_file_name} Cropped Images\")\n",
    "        if not os.path.exists(specific_save_path):\n",
    "            os.makedirs(specific_save_path)\n",
    "\n",
    "        for index, box in enumerate(boxes):\n",
    "            x1 = int(box[0])\n",
    "            y1 = int(box[1])\n",
    "            x2 = int(box[2])\n",
    "            y2 = int(box[3])\n",
    "            x1 = max(0, x1 - buffer)\n",
    "            y1 = max(0, y1 - buffer)\n",
    "            x2 = min(img_cv.shape[1], x2 + buffer)\n",
    "            y2 = min(img_cv.shape[0], y2 + buffer)\n",
    "            \n",
    "            cropped_img = img_cv[y1:y2, x1:x2]\n",
    "            cv2.imwrite(f\"{specific_save_path}/{base_file_name}_table_{index}.png\", cropped_img)\n",
    "\n",
    "    if plot and num_tables > 0:\n",
    "        plot_results(image, results['scores'], results['labels'], results['boxes'])\n",
    "\n",
    "    if len(file_parts) == 2:\n",
    "        return {'FileName': file_parts[0], 'Page Number': file_parts[1], 'Number of tables': num_tables}\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def plot_results(pil_img, scores, labels, boxes):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        text = f'{model.config.id2label[label]}: {score:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "all_data = []\n",
    "\n",
    "for path in concatenated_paths:\n",
    "    if os.path.isdir(path):\n",
    "        df = process_directory(path, plot=False)\n",
    "        all_data.append(df)\n",
    "    elif os.path.isfile(path) and os.path.splitext(path)[1].lower() in VALID_EXTENSIONS:\n",
    "        parent_dir = os.path.dirname(path)  # This is where our cropped images would be saved\n",
    "        data = process_image(path, base_save_path=parent_dir, plot=False)\n",
    "        if data:\n",
    "            all_data.append(pd.DataFrame([data]))\n",
    "\n",
    "# Concatenate all data into the master dataframe\n",
    "master_df = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation of Table Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your DataFrame from table_counts_threshold_099.csv\n",
    "\n",
    "eval_path = DATA_PATH+'/'+'Capstone Project - Table Text Extraction/table_counts_threshold_099.csv'\n",
    "\n",
    "df = pd.read_csv(eval_path)\n",
    "\n",
    "# Define the subset size (number of rows per subset)\n",
    "subset_size = 480  # 480 rows\n",
    "\n",
    "# Calculate the number of subsets to create\n",
    "num_subsets = len(df) // subset_size\n",
    "\n",
    "# Define the subset index to display the confusion matrix (6th subset)\n",
    "display_subset_index = 5  # Indexing starts from 0\n",
    "\n",
    "# Iterate through subsets and calculate performance metrics\n",
    "for i in range(num_subsets):\n",
    "    # Calculate the starting and ending indices for the current subset\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = (i + 1) * subset_size\n",
    "\n",
    "    # Extract the subset of the DataFrame\n",
    "    subset_df = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Extract the \"Table Detected (Model)\" and \"Table Detected (Human)\" columns for this subset\n",
    "    model_detected = subset_df['Table Detected (Model)']\n",
    "    human_detected = subset_df['Table Detected (Human)']\n",
    "\n",
    "    # Filter out any detections over 3 (replace values greater than 3 with 3)\n",
    "    model_detected = np.minimum(model_detected, 3)\n",
    "    human_detected = np.minimum(human_detected, 3)\n",
    "\n",
    "    # Calculate and save accuracy, precision, recall, and F1 score\n",
    "    accuracy = accuracy_score(human_detected, model_detected)\n",
    "    precision = precision_score(human_detected, model_detected, average='weighted', zero_division=0)\n",
    "    recall = recall_score(human_detected, model_detected, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(human_detected, model_detected, average='weighted', zero_division=0)\n",
    "\n",
    "    # Display the start and end rows for this subset\n",
    "    subset_title = 0.9 + i / 100  # Convert index to subset title\n",
    "    print(f'Subset {subset_title:.2f} - Start Row: {start_idx + 1}, End Row: {end_idx}')\n",
    "    print(f'Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}')\n",
    "\n",
    "    # Check if this is the 6th subset (display_subset_index)\n",
    "    if i == display_subset_index:\n",
    "        # Create the confusion matrix for this subset\n",
    "        confusion = confusion_matrix(human_detected, model_detected)\n",
    "\n",
    "        # Define class labels for the confusion matrix (0 to 3)\n",
    "        class_labels_subset = ['0', '1', '2', '3']\n",
    "\n",
    "        # Create a confusion matrix visualization using ConfusionMatrixDisplay with specified labels\n",
    "        disp = ConfusionMatrixDisplay(confusion, display_labels=class_labels_subset)\n",
    "        disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "\n",
    "        plt.title(f'Count Confusion Matrix for Subset {subset_title:.2f}')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the subset size (number of rows per subset)\n",
    "subset_size = 480  # 480 rows\n",
    "\n",
    "# Calculate the number of subsets to create\n",
    "num_subsets = len(df) // subset_size\n",
    "\n",
    "# Define a variable for renaming subsets\n",
    "subset_name = 0.90\n",
    "\n",
    "# Initialize lists to store count and percentage values\n",
    "detected_counts = []\n",
    "none_counts = []\n",
    "equal_counts = []\n",
    "less_counts = []\n",
    "more_counts = []\n",
    "more_misclassified_counts = []\n",
    "\n",
    "# Iterate through subsets and calculate count and percentage values\n",
    "for i in range(num_subsets):\n",
    "    # Calculate the starting and ending indices for the current subset\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = (i + 1) * subset_size\n",
    "\n",
    "    # Extract the subset of the DataFrame\n",
    "    subset_df = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Extract the \"Table Detected (Model)\" and \"Table Detected (Human)\" columns for this subset\n",
    "    model_detected = subset_df['Table Detected (Model)']\n",
    "    human_detected = subset_df['Table Detected (Human)']\n",
    "\n",
    "    # Calculate the count of 'Detected' and 'None' classes\n",
    "    detected_count = ((model_detected > 0) & (human_detected > 0)).sum()\n",
    "    none_count = ((model_detected == 0) & (human_detected == 0)).sum()\n",
    "\n",
    "    # Calculate the count of 'Equal,' 'Less,' and 'More' classes\n",
    "    equal_count = ((model_detected == human_detected) & (model_detected > 0) & (human_detected > 0)).sum()  # Added condition\n",
    "    less_count = ((model_detected < human_detected) & ((model_detected > 0) | (human_detected > 0))).sum()\n",
    "    more_count = ((model_detected > 0) & (human_detected > 0)).sum()  # Modified to consider only both > 0\n",
    "    more_misclassified_count = ((model_detected > human_detected) & (human_detected == 0) & (model_detected > 0)).sum()\n",
    "\n",
    "    # Append the count values to the respective lists\n",
    "    detected_counts.append(detected_count)\n",
    "    none_counts.append(none_count)\n",
    "    equal_counts.append(equal_count)\n",
    "    less_counts.append(less_count)\n",
    "    more_counts.append(more_count)\n",
    "    more_misclassified_counts.append(more_misclassified_count)\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_samples = len(subset_df)\n",
    "    detected_percentage = (detected_count / total_samples) * 100\n",
    "    none_percentage = (none_count / total_samples) * 100\n",
    "    equal_percentage = (equal_count / total_samples) * 100\n",
    "    less_percentage = (less_count / total_samples) * 100\n",
    "    more_percentage = (more_count / total_samples) * 100\n",
    "    more_misclassified_percentage = (more_misclassified_count / total_samples) * 100\n",
    "\n",
    "    # Create strings for printing\n",
    "    count_and_percentage_strings = []\n",
    "    count_and_percentage_strings.append(f\"Subset {subset_name:.2f}:\")\n",
    "    count_and_percentage_strings.append(f\"  Detected: {detected_count}, Detected%: {detected_percentage:.2f}%\")\n",
    "    count_and_percentage_strings.append(f\"  None: {none_count}, None%: {none_percentage:.2f}%\")\n",
    "    count_and_percentage_strings.append(f\"  Equal: {equal_count}, Equal%: {equal_percentage:.2f}%\")\n",
    "    count_and_percentage_strings.append(f\"  Less: {less_count}, Less%: {less_percentage:.2f}%\")\n",
    "    count_and_percentage_strings.append(f\"  More: {more_count}, More%: {more_percentage:.2f}%\")\n",
    "    count_and_percentage_strings.append(f\"  More Misclassified: {more_misclassified_count}, More Misclassified%: {more_misclassified_percentage:.2f}%\")\n",
    "\n",
    "    # Print count and percentage strings\n",
    "    for line in count_and_percentage_strings:\n",
    "        print(line)\n",
    "\n",
    "    # Increment the subset name\n",
    "    subset_name += 0.01\n",
    "\n",
    "# Create four subplots (two for counts and two for percentages) with the original size\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))  # Larger plot size\n",
    "fig.suptitle('Count and Percentage of Classes in Subsets', fontsize=16)\n",
    "\n",
    "\n",
    "# Subplot for counts of 'Detected' and 'None' classes\n",
    "x = np.arange(len(detected_counts))\n",
    "bars_det = axes[0, 0].bar(x, detected_counts, label='Detected', alpha=0.5)\n",
    "bars_none = axes[0, 0].bar(x, none_counts, label='None', alpha=0.5, bottom=detected_counts)\n",
    "axes[0, 0].set_xlabel('Subsets')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Count of Detected and None Classes')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].legend(loc='upper right')  # Legend placed outside the plot\n",
    "axes[0, 0].set_xticklabels([f\"Subset {subset_name:.2f}\" for subset_name in np.arange(0.90, 0.90 + num_subsets * 0.01, 0.01)], rotation=45)\n",
    "\n",
    "# Add labels on the bars for counts of 'Detected' and 'None' classes\n",
    "for bar_det, bar_none, label_det, label_none in zip(bars_det, bars_none, detected_counts, none_counts):\n",
    "    height_det = bar_det.get_height()\n",
    "    height_none = bar_none.get_height()\n",
    "    axes[0, 0].annotate(f'{label_det}', xy=(bar_det.get_x() + bar_det.get_width() / 2, height_det / 2),\n",
    "                       xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[0, 0].annotate(f'{label_none}', xy=(bar_none.get_x() + bar_none.get_width() / 2, height_det + height_none / 2),\n",
    "                       xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "# Subplot for percentages of 'Detected' and 'None' classes\n",
    "x = np.arange(len(detected_counts))\n",
    "detected_percentages = [(count / (count + none_counts[i])) * 100 for i, count in enumerate(detected_counts)]\n",
    "none_percentages = [(count / (count + detected_counts[i])) * 100 for i, count in enumerate(none_counts)]\n",
    "\n",
    "bars_det = axes[0, 1].bar(x, detected_percentages, label='Detected (%)', alpha=0.5)\n",
    "bars_none = axes[0, 1].bar(x, none_percentages, label='None (%)', alpha=0.5, bottom=detected_percentages)\n",
    "axes[0, 1].set_xlabel('Subsets')\n",
    "axes[0, 1].set_ylabel('Percentage (%)')\n",
    "axes[0, 1].set_title('Percentage of Detected and None Classes')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].legend(loc='upper right')  # Legend placed outside the plot\n",
    "axes[0, 1].set_xticklabels([f\"Subset {subset_name:.2f}\" for subset_name in np.arange(0.90, 0.90 + num_subsets * 0.01, 0.01)], rotation=45)\n",
    "\n",
    "# Add labels on the bars for percentages of 'Detected' and 'None' classes\n",
    "for bar_det, bar_none, label_det, label_none in zip(bars_det, bars_none, detected_percentages, none_percentages):\n",
    "    height_det = bar_det.get_height()\n",
    "    height_none = bar_none.get_height()\n",
    "    axes[0, 1].annotate(f'{label_det:.2f}%', xy=(bar_det.get_x() + bar_det.get_width() / 2, height_det / 2),\n",
    "                       xytext=(0, 5), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[0, 1].annotate(f'{label_none:.2f}%', xy=(bar_none.get_x() + bar_none.get_width() / 2, height_det + height_none / 2),\n",
    "                       xytext=(0, 5), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "# Subplot for counts of 'Equal,' 'Less,' 'More,' and 'More Misclassified' classes\n",
    "x = np.arange(len(equal_counts))\n",
    "bars_equal = axes[1, 0].bar(x, equal_counts, label='Equal', alpha=0.5)\n",
    "bars_less = axes[1, 0].bar(x, less_counts, label='Less', alpha=0.5, bottom=equal_counts)\n",
    "bars_more = axes[1, 0].bar(x, more_counts, label='More', alpha=0.5, bottom=np.array(equal_counts) + np.array(less_counts))\n",
    "bars_more_misclassified = axes[1, 0].bar(x, more_misclassified_counts, label='More Misclassified', alpha=0.5,\n",
    "                                          bottom=np.array(equal_counts) + np.array(less_counts) + np.array(more_counts))\n",
    "axes[1, 0].set_xlabel('Subsets')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Count of Equal, Less, More, and More Misclassified Classes')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].legend(loc='upper left', bbox_to_anchor=(1.05, 1))  # Legend placed outside to the right\n",
    "\n",
    "# Add labels on the bars for counts of 'Equal,' 'Less,' 'More,' and 'More Misclassified' classes\n",
    "for bar_equal, bar_less, bar_more, bar_more_misclassified, label_equal, label_less, label_more, label_more_misclassified in zip(\n",
    "        bars_equal, bars_less, bars_more, bars_more_misclassified, equal_counts, less_counts, more_counts, more_misclassified_counts):\n",
    "    height_equal = bar_equal.get_height()\n",
    "    height_less = bar_less.get_height()\n",
    "    height_more = bar_more.get_height()\n",
    "    height_more_misclassified = bar_more_misclassified.get_height()\n",
    "    axes[1, 0].annotate(f'{label_equal}', xy=(bar_equal.get_x() + bar_equal.get_width() / 2, height_equal / 2),\n",
    "                       xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[1, 0].annotate(f'{label_less}', xy=(bar_less.get_x() + bar_less.get_width() / 2, height_equal + height_less / 2),\n",
    "                       xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[1, 0].annotate(f'{label_more}', xy=(bar_more.get_x() + bar_more.get_width() / 2, height_equal + height_less + height_more / 2),\n",
    "                       xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[1, 0].annotate(f'{label_more_misclassified}', xy=(bar_more_misclassified.get_x() + bar_more_misclassified.get_width() / 2,\n",
    "                                                           height_equal + height_less + height_more + height_more_misclassified / 2),\n",
    "                       xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "# Subplot for percentages of 'Equal,' 'Less,' 'More,' and 'More Misclassified' classes\n",
    "x = np.arange(len(equal_counts))\n",
    "equal_percentages = [(count / (count + less_counts[i] + more_counts[i] + more_misclassified_counts[i])) * 100 for i, count in enumerate(equal_counts)]\n",
    "less_percentages = [(count / (count + equal_counts[i] + more_counts[i] + more_misclassified_counts[i])) * 100 for i, count in enumerate(less_counts)]\n",
    "more_percentages = [(count / (count + equal_counts[i] + less_counts[i] + more_misclassified_counts[i])) * 100 for i, count in enumerate(more_counts)]\n",
    "more_misclassified_percentages = [(count / (count + equal_counts[i] + less_counts[i] + more_counts[i])) * 100 for i, count in enumerate(more_misclassified_counts)]\n",
    "\n",
    "bars_equal = axes[1, 1].bar(x, equal_percentages, label='Equal (%)', alpha=0.5)\n",
    "bars_less = axes[1, 1].bar(x, less_percentages, label='Less (%)', alpha=0.5, bottom=equal_percentages)\n",
    "bars_more = axes[1, 1].bar(x, more_percentages, label='More (%)', alpha=0.5,\n",
    "                          bottom=np.array(equal_percentages) + np.array(less_percentages))\n",
    "bars_more_misclassified = axes[1, 1].bar(x, more_misclassified_percentages, label='More Misclassified (%)', alpha=0.5,\n",
    "                                          bottom=np.array(equal_percentages) + np.array(less_percentages) + np.array(more_percentages))\n",
    "axes[1, 1].set_xlabel('Subsets')\n",
    "axes[1, 1].set_ylabel('Percentage (%)')\n",
    "axes[1, 1].set_title('Percentage of Equal, Less, More, and More Misclassified Classes')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].legend(loc='upper left', bbox_to_anchor=(1.05, 1))  # Legend placed outside to the right\n",
    "\n",
    "# Add labels on the bars for percentages of 'Equal,' 'Less,' 'More,' and 'More Misclassified' classes\n",
    "for bar_equal, bar_less, bar_more, bar_more_misclassified, label_equal, label_less, label_more, label_more_misclassified in zip(\n",
    "        bars_equal, bars_less, bars_more, bars_more_misclassified, equal_percentages, less_percentages, more_percentages, more_misclassified_percentages):\n",
    "    height_equal = bar_equal.get_height()\n",
    "    height_less = bar_less.get_height()\n",
    "    height_more = bar_more.get_height()\n",
    "    height_more_misclassified = bar_more_misclassified.get_height()\n",
    "    axes[1, 1].annotate(f'{label_equal:.2f}%', xy=(bar_equal.get_x() + bar_equal.get_width() / 2, height_equal / 2),\n",
    "                       xytext=(0, 5), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[1, 1].annotate(f'{label_less:.2f}%', xy=(bar_less.get_x() + bar_less.get_width() / 2, height_equal + height_less / 2),\n",
    "                       xytext=(0, 5), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[1, 1].annotate(f'{label_more:.2f}%', xy=(bar_more.get_x() + bar_more.get_width() / 2, height_equal + height_less + height_more / 2),\n",
    "                       xytext=(0, 5), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    axes[1, 1].annotate(f'{label_more_misclassified:.2f}%',\n",
    "                       xy=(bar_more_misclassified.get_x() + bar_more_misclassified.get_width() / 2,\n",
    "                           height_equal + height_less + height_more + height_more_misclassified / 2),\n",
    "                       xytext=(0, 5), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Perform Table Data Extraction Using Morphological Operations Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subdirs_with_name(path, keyword):\n",
    "    \"\"\"Return all subdirectories containing the given keyword.\"\"\"\n",
    "    return [os.path.join(root, directory) for root, dirs, files in os.walk(path) for directory in dirs if keyword in directory]\n",
    "\n",
    "def find_image_files_in_dir(path):\n",
    "    \"\"\"Return all image files in the directory.\"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff']\n",
    "    return [os.path.join(root, file) for root, dirs, files in os.walk(path) for file in files if any(file.lower().endswith(ext) for ext in image_extensions)]\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    \n",
    "    img_bin = 255 - image\n",
    "    _, img_bin_otsu = cv2.threshold(img_bin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Vertical Line extraction\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, np.array(img_bin_otsu).shape[1]//150))\n",
    "    eroded_image = cv2.erode(img_bin_otsu, vertical_kernel, iterations=5)\n",
    "    vertical_lines = cv2.dilate(eroded_image, vertical_kernel, iterations=5)\n",
    "    \n",
    "    # Horizontal Line extraction\n",
    "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (np.array(img_bin_otsu).shape[1]//150, 1))\n",
    "    image_2 = cv2.erode(img_bin_otsu, hor_kernel, iterations=5)\n",
    "    horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=5)\n",
    "\n",
    "    # Combining\n",
    "    vertical_horizontal_lines = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    vertical_horizontal_lines = cv2.erode(~vertical_horizontal_lines, kernel, iterations=3)\n",
    "    _, vertical_horizontal_lines = cv2.threshold(vertical_horizontal_lines, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    b_image = cv2.bitwise_not(cv2.bitwise_xor(image, vertical_horizontal_lines))\n",
    "    return b_image, vertical_horizontal_lines\n",
    "\n",
    "\n",
    "def extract_bounding_boxes(b_image, vertical_horizontal_lines):\n",
    "    contours, _ = cv2.findContours(vertical_horizontal_lines, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boundingBoxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    (contours, boundingBoxes) = zip(*sorted(zip(contours, boundingBoxes), key=lambda x: x[1][1]))\n",
    "\n",
    "    boxes = []\n",
    "    image_copy = b_image.copy()  # Initialize image_copy here\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        x-=1\n",
    "        w+=1\n",
    "        if w < 1000 and h < 500:\n",
    "            cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "            boxes.append([x, y, w, h])\n",
    "            \n",
    "    # Uncomment Section to show plots\n",
    "    # plt.imshow(image_copy, cmap='gray')\n",
    "    # plt.title(\"Identified contours\")\n",
    "    # plt.show()\n",
    "    return boxes\n",
    "\n",
    "def extract_text_from_boxes(b_image, boxes):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    heights = [box[3] for box in boxes]  # Extracting the heights of all boxes\n",
    "    mean_height = np.mean(heights)\n",
    "\n",
    "    # Initialize columns list with the first box and set the previous box to the first box\n",
    "    columns.append(boxes[0])\n",
    "    previous_box = boxes[0]\n",
    "\n",
    "    for i in range(1, len(boxes)):\n",
    "        if boxes[i][1] <= previous_box[1] + mean_height / 2:\n",
    "            columns.append(boxes[i])\n",
    "            previous_box = boxes[i]\n",
    "            if i == len(boxes) - 1:\n",
    "                rows.append(columns)\n",
    "        else:\n",
    "            rows.append(columns)\n",
    "            columns = []\n",
    "            previous_box = boxes[i]\n",
    "            columns.append(boxes[i])\n",
    "\n",
    "    # Determine the total number of cells in the row with the maximum cells\n",
    "    total_cells = max([len(r) for r in rows])\n",
    "\n",
    "    # Find the center of each box in the first row\n",
    "    centers = [int(rows[0][j][0] + rows[0][j][2] / 2) for j in range(len(rows[0]))]\n",
    "    centers = np.array(centers)\n",
    "    centers.sort()\n",
    "\n",
    "    # Organize boxes by their closest center position\n",
    "    boxes_list = []\n",
    "    for i in range(len(rows)):\n",
    "        l = [[] for _ in range(total_cells)]\n",
    "        for j in range(len(rows[i])):\n",
    "            # Find the closest center for the current box\n",
    "            diff = abs(centers - (rows[i][j][0] + rows[i][j][2] / 4))\n",
    "            minimum = min(diff)\n",
    "            index = list(diff).index(minimum)\n",
    "            l[index].append(rows[i][j])\n",
    "        boxes_list.append(l)\n",
    "\n",
    "    # Extracting text from cells in the image\n",
    "    dataframe_final = []\n",
    "    for i in range(len(boxes_list)):\n",
    "        for j in range(len(boxes_list[i])):\n",
    "            s = ''\n",
    "            if len(boxes_list[i][j]) == 0:\n",
    "                dataframe_final.append(' ')\n",
    "            else:\n",
    "                for k in range(len(boxes_list[i][j])):\n",
    "                    x, y, w, h = boxes_list[i][j][k]\n",
    "                    roi = b_image[y:y+h, x:x+w]\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))\n",
    "                    border = cv2.copyMakeBorder(roi, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=[255, 255])\n",
    "                    resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "                    dilation = cv2.dilate(resizing, kernel, iterations=1)\n",
    "                    erosion = cv2.erode(dilation, kernel, iterations=2)\n",
    "                    out = pytesseract.image_to_string(erosion).strip()\n",
    "                    s += \" \" + out\n",
    "                dataframe_final.append(s)\n",
    "\n",
    "    arr = np.array(dataframe_final)\n",
    "    dataframe = pd.DataFrame(arr.reshape(len(rows), total_cells))\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def ocr_image_to_text(image_path, extracted_dir):\n",
    "    b_image, vertical_horizontal_lines = process_image(image_path)\n",
    "    boxes = extract_bounding_boxes(b_image, vertical_horizontal_lines)\n",
    "\n",
    "    if len(boxes) <= 1:\n",
    "        print(\"No Table Detected.\")\n",
    "        return  # No need to return the counter\n",
    "    else:\n",
    "        print('Table Extracted!')\n",
    "        dataframe = extract_text_from_boxes(b_image, boxes)\n",
    "        \n",
    "        output_dir = os.path.dirname(extracted_dir)\n",
    "        # Extract filename without extension and \"Cropped Images\" part\n",
    "        file_name_without_ext = os.path.basename(image_path).rsplit('.', 1)[0]\n",
    "        file_name_without_cropped = file_name_without_ext.replace(\" Cropped Images\", \"\")\n",
    "        \n",
    "        csv_output_path = os.path.join(output_dir, f\"{file_name_without_cropped}.csv\")\n",
    "        \n",
    "        dataframe.to_csv(csv_output_path, index=False, header=False)\n",
    "\n",
    "def process_images_in_extracted_dirs(main_wd, output_dir):\n",
    "    cropped_dirs = find_subdirs_with_name(main_wd, \"Cropped\")\n",
    "    for extracted_dir in cropped_dirs:\n",
    "        for image_path in find_image_files_in_dir(extracted_dir):\n",
    "            ocr_image_to_text(image_path, extracted_dir)\n",
    "\n",
    "\n",
    "## Use of Extractor\n",
    "main_wd = working_directory\n",
    "output_directory = os.path.dirname(main_wd)\n",
    "process_images_in_extracted_dirs(main_wd, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Perform Table Data Extraction Using Paddle OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
